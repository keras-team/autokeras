{
    "docs": [
        {
            "location": "/",
            "text": "Auto-Keras is an open source software library for automated machine learning (AutoML). The ultimate goal of AutoML is to allow domain experts with limited data science or machine learning background easily accessible to deep learning models.\nAuto-Keras provides functions to automatically search for architecture and hyperparameters of deep learning models.\n\n\nInstallation\n\n\nTo install the package, please use the \npip\n installation as follows:\n\n\npip install autokeras\n\n\n\nExample\n\n\nHere is a short example of using the package.\n\n\nimport autokeras as ak\n\nclf = ak.ImageClassifier()\nclf.fit(x_train, y_train)\nresults = clf.predict(x_test)\n\n\n\nDocumentation\n\n\nFor the documentation, please visit the \nAuto-Keras\n official website.\n\n\nCiting this work\n\n\nIf you use Auto-Keras in a scientific publication, you are highly encouraged (though not required) to cite the following paper:\n\n\nEfficient Neural Architecture Search with Network Morphism.\nHaifeng Jin, Qingquan Song, and Xia Hu.\n\narXiv:1806.10282\n.\n\n\nBiblatex entry:\n\n\n@online{jin2018efficient,\n  author       = {Haifeng Jin and Qingquan Song and Xia Hu},\n  title        = {Efficient Neural Architecture Search with Network Morphism},\n  date         = {2018-06-27},\n  year         = {2018},\n  eprintclass  = {cs.LG},\n  eprinttype   = {arXiv},\n  eprint       = {cs.LG/1806.10282},\n}\n\n\n\nDISCLAIMER\n\n\nPlease note that this is a \npre-release\n version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an\n\u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does \nnot\n give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will \nnot\n  be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or\nother problems on the website, please let us know immediately so we\ncan rectify these accordingly. Your help in this regard is greatly\nappreciated.",
            "title": "Home"
        },
        {
            "location": "/#installation",
            "text": "To install the package, please use the  pip  installation as follows:  pip install autokeras",
            "title": "Installation"
        },
        {
            "location": "/#example",
            "text": "Here is a short example of using the package.  import autokeras as ak\n\nclf = ak.ImageClassifier()\nclf.fit(x_train, y_train)\nresults = clf.predict(x_test)",
            "title": "Example"
        },
        {
            "location": "/#documentation",
            "text": "For the documentation, please visit the  Auto-Keras  official website.",
            "title": "Documentation"
        },
        {
            "location": "/#citing-this-work",
            "text": "If you use Auto-Keras in a scientific publication, you are highly encouraged (though not required) to cite the following paper:  Efficient Neural Architecture Search with Network Morphism.\nHaifeng Jin, Qingquan Song, and Xia Hu. arXiv:1806.10282 .  Biblatex entry:  @online{jin2018efficient,\n  author       = {Haifeng Jin and Qingquan Song and Xia Hu},\n  title        = {Efficient Neural Architecture Search with Network Morphism},\n  date         = {2018-06-27},\n  year         = {2018},\n  eprintclass  = {cs.LG},\n  eprinttype   = {arXiv},\n  eprint       = {cs.LG/1806.10282},\n}",
            "title": "Citing this work"
        },
        {
            "location": "/#disclaimer",
            "text": "Please note that this is a  pre-release  version of the Auto-Keras which is still undergoing final testing before its official release. The website, its software and all content found on it are provided on an\n\u201cas is\u201d and \u201cas available\u201d basis. Auto-Keras does  not  give any warranties, whether express or implied, as to the suitability or usability of the website, its software or any of its content. Auto-Keras will  not   be liable for any loss, whether such loss is direct, indirect, special or consequential, suffered by any party as a result of their use of the libraries or content. Any usage of the libraries is done at the user\u2019s own risk and the user will be solely responsible for any damage to any computer system or loss of data that results from such activities. Should you encounter any bugs, glitches, lack of functionality or\nother problems on the website, please let us know immediately so we\ncan rectify these accordingly. Your help in this regard is greatly\nappreciated.",
            "title": "DISCLAIMER"
        },
        {
            "location": "/start/",
            "text": "Getting Started\n\n\nInstallation\n\n\nThe installation of Auto-Keras is the same as other python packages. Notably, currently we only support Python 3.6.\n\n\nLatest Stable Version (\npip\n installation):\n\n\nYou can run the following \npip\n installation command in your terminal to install the latest stable version.\n\n\npip install autokeras\n\n\n\nBleeding Edge Version (manual installation):\n\n\nIf you want to install the latest development version. \nYou need to download the code from the GitHub repo and run the following commands in the project directory.\n\n\npip install -r requirements.txt\npython setup.py install\n\n\n\nExample\n\n\nWe show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs. \n\n\nData with numpy array (.npy) format.\n\n\nIf the images and the labels are already formatted into numpy arrays, you can \n\n\nfrom keras.datasets import mnist\nfrom autokeras.classifier import ImageClassifier\n\nif __name__ == '__main__':\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = x_train.reshape(x_train.shape + (1,))\n    x_test = x_test.reshape(x_test.shape + (1,))\n\n    clf = ImageClassifier(verbose=True)\n    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)\n    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)\n    y = clf.evaluate(x_test, y_test)\n    print(y)\n\n\n\nIn the example above, the images and the labels are already formatted into numpy arrays.\n\n\nWhat if your data are raw image files (\ne.g.\n .jpg, .png, .bmp)?\n\n\nYou can use our \nload_image_dataset\n function to load the images and there labels as follows.\n\n\nfrom autokeras.classifier import load_image_dataset\n\nx_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\",\n                                      images_path=\"train\")\nprint(x_train.shape)\nprint(y_train.shape)\n\nx_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\",\n                                    images_path=\"test\")\nprint(x_test.shape)\nprint(y_test.shape)\n\n\n\nThe argument \ncsv_file_path\n is the path to the CSV file containing the image file names and their corresponding labels.\nHere is an example of the csv file.\n\n\nFile Name,Label\n00000.jpg,5\n00001.jpg,0\n00002.jpg,4\n00003.jpg,1\n00004.jpg,9\n00005.jpg,2\n00006.jpg,1\n...\n\n\n\nThe second argument \nimages_path\n is the path to the directory containing all the images with those file names listed in the CSV file.\nThe returned values \nx_train\n and \ny_train\n are the numpy arrays,\nwhich can be directly feed into the \nfit\n function of \nImageClassifier\n.",
            "title": "Getting Started"
        },
        {
            "location": "/start/#getting-started",
            "text": "",
            "title": "Getting Started"
        },
        {
            "location": "/start/#installation",
            "text": "The installation of Auto-Keras is the same as other python packages. Notably, currently we only support Python 3.6.",
            "title": "Installation"
        },
        {
            "location": "/start/#latest-stable-version-pip-installation",
            "text": "You can run the following  pip  installation command in your terminal to install the latest stable version.  pip install autokeras",
            "title": "Latest Stable Version (pip installation):"
        },
        {
            "location": "/start/#bleeding-edge-version-manual-installation",
            "text": "If you want to install the latest development version. \nYou need to download the code from the GitHub repo and run the following commands in the project directory.  pip install -r requirements.txt\npython setup.py install",
            "title": "Bleeding Edge Version (manual installation):"
        },
        {
            "location": "/start/#example",
            "text": "We show an example of image classification on the MNIST dataset, which is a famous benchmark image dataset for hand-written digits classification. Auto-Keras supports different types of data inputs.",
            "title": "Example"
        },
        {
            "location": "/start/#data-with-numpy-array-npy-format",
            "text": "If the images and the labels are already formatted into numpy arrays, you can   from keras.datasets import mnist\nfrom autokeras.classifier import ImageClassifier\n\nif __name__ == '__main__':\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = x_train.reshape(x_train.shape + (1,))\n    x_test = x_test.reshape(x_test.shape + (1,))\n\n    clf = ImageClassifier(verbose=True)\n    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)\n    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)\n    y = clf.evaluate(x_test, y_test)\n    print(y)  In the example above, the images and the labels are already formatted into numpy arrays.",
            "title": "Data with numpy array (.npy) format."
        },
        {
            "location": "/start/#what-if-your-data-are-raw-image-files-eg-jpg-png-bmp",
            "text": "You can use our  load_image_dataset  function to load the images and there labels as follows.  from autokeras.classifier import load_image_dataset\n\nx_train, y_train = load_image_dataset(csv_file_path=\"train/label.csv\",\n                                      images_path=\"train\")\nprint(x_train.shape)\nprint(y_train.shape)\n\nx_test, y_test = load_image_dataset(csv_file_path=\"test/label.csv\",\n                                    images_path=\"test\")\nprint(x_test.shape)\nprint(y_test.shape)  The argument  csv_file_path  is the path to the CSV file containing the image file names and their corresponding labels.\nHere is an example of the csv file.  File Name,Label\n00000.jpg,5\n00001.jpg,0\n00002.jpg,4\n00003.jpg,1\n00004.jpg,9\n00005.jpg,2\n00006.jpg,1\n...  The second argument  images_path  is the path to the directory containing all the images with those file names listed in the CSV file.\nThe returned values  x_train  and  y_train  are the numpy arrays,\nwhich can be directly feed into the  fit  function of  ImageClassifier .",
            "title": "What if your data are raw image files (e.g. .jpg, .png, .bmp)?"
        },
        {
            "location": "/classifier/",
            "text": "_validate\n\n\nCheck x_train's type and the shape of x_train, y_train.\n\n\nread_csv_file\n\n\nRead the cvs file and returns two seperate list containing images name and their labels\n\n\nArgs\n\n\ncsv_file_path\n: Path to the CVS file.\n\n\nReturns\n\n\nimg_file_names list containing images names and img_label list containing their respective labels.\n\n\nread_images\n\n\nReads the images from the path and return there numpy.ndarray instance\n\n\nArgs\n\n\nimg_file_names\n: List containing images names\n\n\nimages_dir_path\n: Path to directory containing images\n\n\nload_image_dataset\n\n\nLoad images from the files and labels from a csv file.\nSecond, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path. The path to the directory containing all the images should be passed through image_path.\n\n\nArgs\n\n\ncsv_file_path\n: CVS file path.\n\n\nimages_path\n: Path where images exist.\n\n\nReturns\n\n\nx: Four dimensional numpy.ndarray. The channel dimension is the last dimension. y: The labels.\n\n\nImageClassifier\n\n\nThe image classifier class.\nIt is used for image classification. It searches convolutional neural network architectures for the best configuration for the dataset.\n\n\nAttributes\n\n\npath\n: A path to the directory to save the classifier.\n\n\ny_encoder\n: An instance of OneHotEncoder for y_train (array of categorical labels).\n\n\nverbose\n: A boolean value indicating the verbosity mode.\n\n\nsearcher\n: An instance of BayesianSearcher. It search different\n    neural architecture to find the best model.\n\n\nsearcher_args\n: A dictionary containing the parameters for the searcher's \ninit\n function.\n\n\naugment\n: A boolean value indicating whether the data needs augmentation.\n\n\ninit\n\n\nInitialize the instance.\nThe classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.\n\n\nArgs\n\n\nverbose\n: An boolean of whether the search process will be printed to stdout.\n\n\npath\n: A string. The path to a directory, where the intermediate results are saved.\n\n\nresume\n: An boolean. If True, the classifier will continue to previous work saved in path.\n    Otherwise, the classifier will start a new search.\n\n\naugment\n: A boolean value indicating whether the data needs augmentation.\n\n\nfit\n\n\nFind the best neural architecture and train it.\nBased on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train, y_train.\n\n\nArgs\n\n\nx_train\n: An numpy.ndarray instance contains the training data.\n\n\ny_train\n: An numpy.ndarray instance contains the label of the training data.\n\n\ntime_limit\n: The time limit for the search in seconds.\n\n\npredict\n\n\nReturn predict result for the testing data.\n\n\nArgs\n\n\nx_test\n: An instance of numpy.ndarray contains the testing data.\n\n\nReturns\n\n\nAn numpy.ndarray containing the results.\n\n\nevaluate\n\n\nReturn the accuracy score between predict value and test_y.\n\n\nfinal_fit\n\n\nFinal training after found the best architecture.\n\n\nArgs\n\n\nx_train\n: An numpy.ndarray of training data.\n\n\ny_train\n: An numpy.ndarray of training targets.\n\n\nx_test\n: An numpy.ndarray of testing data.\n\n\ny_test\n: An numpy.ndarray of testing targets.\n\n\ntrainer_args\n: A dictionary containing the parameters of the ModelTrainer constructure.\n\n\nretrain\n: A boolean of whether reinitialize the weights of the model.\n\n\nget_best_model_id\n\n\nReturns: An integer. The best model id.",
            "title": "classifier"
        },
        {
            "location": "/classifier/#_validate",
            "text": "Check x_train's type and the shape of x_train, y_train.",
            "title": "_validate"
        },
        {
            "location": "/classifier/#read_csv_file",
            "text": "Read the cvs file and returns two seperate list containing images name and their labels",
            "title": "read_csv_file"
        },
        {
            "location": "/classifier/#args",
            "text": "csv_file_path : Path to the CVS file.",
            "title": "Args"
        },
        {
            "location": "/classifier/#returns",
            "text": "img_file_names list containing images names and img_label list containing their respective labels.",
            "title": "Returns"
        },
        {
            "location": "/classifier/#read_images",
            "text": "Reads the images from the path and return there numpy.ndarray instance",
            "title": "read_images"
        },
        {
            "location": "/classifier/#args_1",
            "text": "img_file_names : List containing images names  images_dir_path : Path to directory containing images",
            "title": "Args"
        },
        {
            "location": "/classifier/#load_image_dataset",
            "text": "Load images from the files and labels from a csv file.\nSecond, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path. The path to the directory containing all the images should be passed through image_path.",
            "title": "load_image_dataset"
        },
        {
            "location": "/classifier/#args_2",
            "text": "csv_file_path : CVS file path.  images_path : Path where images exist.",
            "title": "Args"
        },
        {
            "location": "/classifier/#returns_1",
            "text": "x: Four dimensional numpy.ndarray. The channel dimension is the last dimension. y: The labels.",
            "title": "Returns"
        },
        {
            "location": "/classifier/#imageclassifier",
            "text": "The image classifier class.\nIt is used for image classification. It searches convolutional neural network architectures for the best configuration for the dataset.",
            "title": "ImageClassifier"
        },
        {
            "location": "/classifier/#attributes",
            "text": "path : A path to the directory to save the classifier.  y_encoder : An instance of OneHotEncoder for y_train (array of categorical labels).  verbose : A boolean value indicating the verbosity mode.  searcher : An instance of BayesianSearcher. It search different\n    neural architecture to find the best model.  searcher_args : A dictionary containing the parameters for the searcher's  init  function.  augment : A boolean value indicating whether the data needs augmentation.",
            "title": "Attributes"
        },
        {
            "location": "/classifier/#init",
            "text": "Initialize the instance.\nThe classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.",
            "title": "init"
        },
        {
            "location": "/classifier/#args_3",
            "text": "verbose : An boolean of whether the search process will be printed to stdout.  path : A string. The path to a directory, where the intermediate results are saved.  resume : An boolean. If True, the classifier will continue to previous work saved in path.\n    Otherwise, the classifier will start a new search.  augment : A boolean value indicating whether the data needs augmentation.",
            "title": "Args"
        },
        {
            "location": "/classifier/#fit",
            "text": "Find the best neural architecture and train it.\nBased on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train, y_train.",
            "title": "fit"
        },
        {
            "location": "/classifier/#args_4",
            "text": "x_train : An numpy.ndarray instance contains the training data.  y_train : An numpy.ndarray instance contains the label of the training data.  time_limit : The time limit for the search in seconds.",
            "title": "Args"
        },
        {
            "location": "/classifier/#predict",
            "text": "Return predict result for the testing data.",
            "title": "predict"
        },
        {
            "location": "/classifier/#args_5",
            "text": "x_test : An instance of numpy.ndarray contains the testing data.",
            "title": "Args"
        },
        {
            "location": "/classifier/#returns_2",
            "text": "An numpy.ndarray containing the results.",
            "title": "Returns"
        },
        {
            "location": "/classifier/#evaluate",
            "text": "Return the accuracy score between predict value and test_y.",
            "title": "evaluate"
        },
        {
            "location": "/classifier/#final_fit",
            "text": "Final training after found the best architecture.",
            "title": "final_fit"
        },
        {
            "location": "/classifier/#args_6",
            "text": "x_train : An numpy.ndarray of training data.  y_train : An numpy.ndarray of training targets.  x_test : An numpy.ndarray of testing data.  y_test : An numpy.ndarray of testing targets.  trainer_args : A dictionary containing the parameters of the ModelTrainer constructure.  retrain : A boolean of whether reinitialize the weights of the model.",
            "title": "Args"
        },
        {
            "location": "/classifier/#get_best_model_id",
            "text": "Returns: An integer. The best model id.",
            "title": "get_best_model_id"
        },
        {
            "location": "/search/",
            "text": "BayesianSearcher\n\n\nBase class of all searcher class\nThis class is the base class of all searcher class, every searcher class can override its search function to implements its strategy\n\n\nAttributes\n\n\nn_classes\n: number of classification\n\n\ninput_shape\n: Arbitrary, although all dimensions in the input shaped must be fixed.\n    Use the keyword argument input_shape (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.\n\n\nverbose\n: verbosity mode\n\n\nhistory\n: A list that stores the performance of model. Each element in it is a dictionary of 'model_id',\n    'loss', and 'accuracy'.\n\n\npath\n: A string. The path to the directory for saving the searcher.\n\n\nmodel_count\n: An integer. the total number of neural networks in the current searcher.\n\n\ndescriptors\n: A dictionary of all the neural networks architectures searched.\n\n\ntrainer_args\n: A dictionary. The params for the constructor of ModelTrainer.\n\n\ndefault_model_len\n: An integer. Number of convolutional layers in the initial architecture.\n\n\ndefault_model_width\n: An integer. The number of filters in each layer in the initial architecture.\n\n\ngpr\n: A GaussianProcessRegressor for bayesian optimization.\n\n\nsearch_tree\n: The data structure for storing all the searched architectures in tree structure.\n\n\ntraining_queue\n: A list of the generated architectures to be trained.\n\n\nx_queue\n: A list of trained architectures not updated to the gpr.\n\n\ny_queue\n: A list of trained architecture performances not updated to the gpr.\n\n\nbeta\n: A float. The beta in the UCB acquisition function.\n\n\nt_min\n: A float. The minimum temperature during simulated annealing.\n\n\ninit\n\n\nArgs: n_classes: An integer, the number of classes. input_shape: A tuple. e.g. (28, 28, 1). path: A string. The path to the directory to save the searcher. verbose: A boolean. Whether to output the intermediate information to stdout. trainer_args: A dictionary. The params for the constructor of ModelTrainer. default_model_len: An integer. Number of convolutional layers in the initial architecture. default_model_width: An integer. The number of filters in each layer in the initial architecture. beta: A float. The beta in the UCB acquisition function. kernel_lambda: A float. The balance factor in the neural network kernel. t_min: A float. The minimum temperature during simulated annealing.",
            "title": "search"
        },
        {
            "location": "/search/#bayesiansearcher",
            "text": "Base class of all searcher class\nThis class is the base class of all searcher class, every searcher class can override its search function to implements its strategy",
            "title": "BayesianSearcher"
        },
        {
            "location": "/search/#attributes",
            "text": "n_classes : number of classification  input_shape : Arbitrary, although all dimensions in the input shaped must be fixed.\n    Use the keyword argument input_shape (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.  verbose : verbosity mode  history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id',\n    'loss', and 'accuracy'.  path : A string. The path to the directory for saving the searcher.  model_count : An integer. the total number of neural networks in the current searcher.  descriptors : A dictionary of all the neural networks architectures searched.  trainer_args : A dictionary. The params for the constructor of ModelTrainer.  default_model_len : An integer. Number of convolutional layers in the initial architecture.  default_model_width : An integer. The number of filters in each layer in the initial architecture.  gpr : A GaussianProcessRegressor for bayesian optimization.  search_tree : The data structure for storing all the searched architectures in tree structure.  training_queue : A list of the generated architectures to be trained.  x_queue : A list of trained architectures not updated to the gpr.  y_queue : A list of trained architecture performances not updated to the gpr.  beta : A float. The beta in the UCB acquisition function.  t_min : A float. The minimum temperature during simulated annealing.",
            "title": "Attributes"
        },
        {
            "location": "/search/#init",
            "text": "Args: n_classes: An integer, the number of classes. input_shape: A tuple. e.g. (28, 28, 1). path: A string. The path to the directory to save the searcher. verbose: A boolean. Whether to output the intermediate information to stdout. trainer_args: A dictionary. The params for the constructor of ModelTrainer. default_model_len: An integer. Number of convolutional layers in the initial architecture. default_model_width: An integer. The number of filters in each layer in the initial architecture. beta: A float. The beta in the UCB acquisition function. kernel_lambda: A float. The balance factor in the neural network kernel. t_min: A float. The minimum temperature during simulated annealing.",
            "title": "init"
        },
        {
            "location": "/graph/",
            "text": "Graph\n\n\nA class represent the neural architecture graph of a Keras model.\nGraph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph.  Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.)\n\n\nAttributes\n\n\nweighted\n: A boolean of whether the weights and biases in the neural network\n    should be included in the graph.\n\n\ninput_shape\n: Tuple of integers, does not include the batch axis.\n\n\nnode_list\n: A list of integers, the indices of the list are the identifiers.\n\n\nlayer_list\n: A list of stub layers, the indices of the list are the identifiers.\n\n\nnode_to_id\n: A dict instance mapping from node integers to their identifiers.\n\n\nlayer_to_id\n: A dict instance mapping from stub layers to their identifiers.\n\n\nlayer_id_to_input_node_ids\n: A dict instance mapping from layer identifiers\n    to their input nodes identifiers.\n\n\nadj_list\n: A two dimensional list. The adjacency list of the graph. The first dimension is\n    identified by tensor identifiers. In each edge list, the elements are two-element tuples\n    of (tensor identifier, layer identifier).\n\n\nreverse_adj_list\n: A reverse adjacent list in the same format as adj_list.\n\n\noperation_history\n: A list saving all the network morphism operations.\n\n\nvis\n: A dictionary of temporary storage for whether an local operation has been done\n    during the network morphism.\n\n\nn_nodes\n\n\nReturn the number of nodes in the model.\n\n\nn_layers\n\n\nReturn the number of layers in the model.\n\n\n_add_node\n\n\nAdd node to node list if it not in node list.\n\n\n_add_edge\n\n\nAdd edge to the graph.\n\n\n_redirect_edge\n\n\nRedirect the edge to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same.\n\n\n_replace_layer\n\n\nReplace the layer with a new layer.\n\n\ntopological_order\n\n\nReturn the topological order of the node ids.\n\n\n_search\n\n\nSearch the graph for widening the layers.\n\n\nArgs\n\n\nu\n: The starting node identifier.\n\n\nstart_dim\n: The position to insert the additional dimensions.\n\n\ntotal_dim\n: The total number of dimensions the layer has before widening.\n\n\nn_add\n: The number of dimensions to add.\n\n\nto_conv_deeper_model\n\n\nInsert a relu-conv-bn block after the target block.\n\n\nArgs\n\n\ntarget_id\n: A convolutional layer ID. The new block should be inserted after the block.\n\n\nkernel_size\n: An integer. The kernel size of the new convolutional layer.\n\n\nto_wider_model\n\n\nWiden the last dimension of the output of the pre_layer.\n\n\nArgs\n\n\npre_layer_id\n: The ID of a convolutional layer or dense layer.\n\n\nn_add\n: The number of dimensions to add.\n\n\nto_dense_deeper_model\n\n\nInsert a dense layer after the target layer.\n\n\nArgs\n\n\ntarget_id\n: The ID of a dense layer.\n\n\n_conv_block_end_node\n\n\nGet the input node ID of the last layer in the block by layer ID.\n\n\nArgs\n\n\nlayer_id\n: the convolutional layer ID.\n\n\nReturns\n\n\nThe input node ID of the last layer in the convolutional block.\n\n\nto_add_skip_model\n\n\nAdd a weighted add skip connection from after start node to end node.\n\n\nArgs\n\n\nstart_id\n: The convolutional layer ID, after which to start the skip-connection.\n\n\nend_id\n: The convolutional layer ID, after which to end the skip-connection.\n\n\nto_concat_skip_model\n\n\nAdd a weighted add concatenate connection from after start node to end node.\n\n\nArgs\n\n\nstart_id\n: The convolutional layer ID, after which to start the skip-connection.\n\n\nend_id\n: The convolutional layer ID, after which to end the skip-connection.\n\n\nproduce_model\n\n\nBuild a new model based on the current graph.",
            "title": "graph"
        },
        {
            "location": "/graph/#graph",
            "text": "A class represent the neural architecture graph of a Keras model.\nGraph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph.  Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.)",
            "title": "Graph"
        },
        {
            "location": "/graph/#attributes",
            "text": "weighted : A boolean of whether the weights and biases in the neural network\n    should be included in the graph.  input_shape : Tuple of integers, does not include the batch axis.  node_list : A list of integers, the indices of the list are the identifiers.  layer_list : A list of stub layers, the indices of the list are the identifiers.  node_to_id : A dict instance mapping from node integers to their identifiers.  layer_to_id : A dict instance mapping from stub layers to their identifiers.  layer_id_to_input_node_ids : A dict instance mapping from layer identifiers\n    to their input nodes identifiers.  adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is\n    identified by tensor identifiers. In each edge list, the elements are two-element tuples\n    of (tensor identifier, layer identifier).  reverse_adj_list : A reverse adjacent list in the same format as adj_list.  operation_history : A list saving all the network morphism operations.  vis : A dictionary of temporary storage for whether an local operation has been done\n    during the network morphism.",
            "title": "Attributes"
        },
        {
            "location": "/graph/#n_nodes",
            "text": "Return the number of nodes in the model.",
            "title": "n_nodes"
        },
        {
            "location": "/graph/#n_layers",
            "text": "Return the number of layers in the model.",
            "title": "n_layers"
        },
        {
            "location": "/graph/#_add_node",
            "text": "Add node to node list if it not in node list.",
            "title": "_add_node"
        },
        {
            "location": "/graph/#_add_edge",
            "text": "Add edge to the graph.",
            "title": "_add_edge"
        },
        {
            "location": "/graph/#_redirect_edge",
            "text": "Redirect the edge to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same.",
            "title": "_redirect_edge"
        },
        {
            "location": "/graph/#_replace_layer",
            "text": "Replace the layer with a new layer.",
            "title": "_replace_layer"
        },
        {
            "location": "/graph/#topological_order",
            "text": "Return the topological order of the node ids.",
            "title": "topological_order"
        },
        {
            "location": "/graph/#_search",
            "text": "Search the graph for widening the layers.",
            "title": "_search"
        },
        {
            "location": "/graph/#args",
            "text": "u : The starting node identifier.  start_dim : The position to insert the additional dimensions.  total_dim : The total number of dimensions the layer has before widening.  n_add : The number of dimensions to add.",
            "title": "Args"
        },
        {
            "location": "/graph/#to_conv_deeper_model",
            "text": "Insert a relu-conv-bn block after the target block.",
            "title": "to_conv_deeper_model"
        },
        {
            "location": "/graph/#args_1",
            "text": "target_id : A convolutional layer ID. The new block should be inserted after the block.  kernel_size : An integer. The kernel size of the new convolutional layer.",
            "title": "Args"
        },
        {
            "location": "/graph/#to_wider_model",
            "text": "Widen the last dimension of the output of the pre_layer.",
            "title": "to_wider_model"
        },
        {
            "location": "/graph/#args_2",
            "text": "pre_layer_id : The ID of a convolutional layer or dense layer.  n_add : The number of dimensions to add.",
            "title": "Args"
        },
        {
            "location": "/graph/#to_dense_deeper_model",
            "text": "Insert a dense layer after the target layer.",
            "title": "to_dense_deeper_model"
        },
        {
            "location": "/graph/#args_3",
            "text": "target_id : The ID of a dense layer.",
            "title": "Args"
        },
        {
            "location": "/graph/#_conv_block_end_node",
            "text": "Get the input node ID of the last layer in the block by layer ID.",
            "title": "_conv_block_end_node"
        },
        {
            "location": "/graph/#args_4",
            "text": "layer_id : the convolutional layer ID.",
            "title": "Args"
        },
        {
            "location": "/graph/#returns",
            "text": "The input node ID of the last layer in the convolutional block.",
            "title": "Returns"
        },
        {
            "location": "/graph/#to_add_skip_model",
            "text": "Add a weighted add skip connection from after start node to end node.",
            "title": "to_add_skip_model"
        },
        {
            "location": "/graph/#args_5",
            "text": "start_id : The convolutional layer ID, after which to start the skip-connection.  end_id : The convolutional layer ID, after which to end the skip-connection.",
            "title": "Args"
        },
        {
            "location": "/graph/#to_concat_skip_model",
            "text": "Add a weighted add concatenate connection from after start node to end node.",
            "title": "to_concat_skip_model"
        },
        {
            "location": "/graph/#args_6",
            "text": "start_id : The convolutional layer ID, after which to start the skip-connection.  end_id : The convolutional layer ID, after which to end the skip-connection.",
            "title": "Args"
        },
        {
            "location": "/graph/#produce_model",
            "text": "Build a new model based on the current graph.",
            "title": "produce_model"
        },
        {
            "location": "/preprocessor/",
            "text": "OneHotEncoder\n\n\nA class that can format data\nThis class provide ways to transform data's classification into vector\n\n\nAttributes\n\n\ndata\n: the input data\n\n\nn_classes\n: the number of classification\n\n\nlabels\n: the number of label\n\n\nlabel_to_vec\n: mapping from label to vector\n\n\nint_to_label\n: mapping from int to label\n\n\ninit\n\n\nInit OneHotEncoder\n\n\nfit\n\n\nCreate mapping from label to vector, and vector to label\n\n\ntransform\n\n\nGet vector for every element in the data array\n\n\ninverse_transform\n\n\nGet label for every element in data",
            "title": "preprocessor"
        },
        {
            "location": "/preprocessor/#onehotencoder",
            "text": "A class that can format data\nThis class provide ways to transform data's classification into vector",
            "title": "OneHotEncoder"
        },
        {
            "location": "/preprocessor/#attributes",
            "text": "data : the input data  n_classes : the number of classification  labels : the number of label  label_to_vec : mapping from label to vector  int_to_label : mapping from int to label",
            "title": "Attributes"
        },
        {
            "location": "/preprocessor/#init",
            "text": "Init OneHotEncoder",
            "title": "init"
        },
        {
            "location": "/preprocessor/#fit",
            "text": "Create mapping from label to vector, and vector to label",
            "title": "fit"
        },
        {
            "location": "/preprocessor/#transform",
            "text": "Get vector for every element in the data array",
            "title": "transform"
        },
        {
            "location": "/preprocessor/#inverse_transform",
            "text": "Get label for every element in data",
            "title": "inverse_transform"
        },
        {
            "location": "/utils/",
            "text": "ensure_dir\n\n\nCreate directory if it does not exist\n\n\nensure_file_dir\n\n\nCreate path if it does not exist\n\n\nModelTrainer\n\n\nA class that is used to train model\nThis class can train a model with dataset and will not stop until getting minimum loss\n\n\nAttributes\n\n\nmodel\n: the model that will be trained\n\n\ntrain_data\n: training data wrapped in batches.\n\n\ntest_data\n: testing data wrapped in batches.\n\n\nverbose\n: verbosity mode\n\n\ninit\n\n\nInit ModelTrainer with model, x_train, y_train, x_test, y_test, verbose\n\n\ntrain_model\n\n\nTrain the model.\n\n\nArgs\n\n\nmax_iter_num\n: An integer. The maximum number of epochs to train the model.\n    The training will stop when this number is reached.\n\n\nmax_no_improvement_num\n: An integer. The maximum number of epochs when the loss value doesn't decrease.\n    The training will stop when this number is reached.\n\n\nbatch_size\n: An integer. The batch size during the training.",
            "title": "utils"
        },
        {
            "location": "/utils/#ensure_dir",
            "text": "Create directory if it does not exist",
            "title": "ensure_dir"
        },
        {
            "location": "/utils/#ensure_file_dir",
            "text": "Create path if it does not exist",
            "title": "ensure_file_dir"
        },
        {
            "location": "/utils/#modeltrainer",
            "text": "A class that is used to train model\nThis class can train a model with dataset and will not stop until getting minimum loss",
            "title": "ModelTrainer"
        },
        {
            "location": "/utils/#attributes",
            "text": "model : the model that will be trained  train_data : training data wrapped in batches.  test_data : testing data wrapped in batches.  verbose : verbosity mode",
            "title": "Attributes"
        },
        {
            "location": "/utils/#init",
            "text": "Init ModelTrainer with model, x_train, y_train, x_test, y_test, verbose",
            "title": "init"
        },
        {
            "location": "/utils/#train_model",
            "text": "Train the model.",
            "title": "train_model"
        },
        {
            "location": "/utils/#args",
            "text": "max_iter_num : An integer. The maximum number of epochs to train the model.\n    The training will stop when this number is reached.  max_no_improvement_num : An integer. The maximum number of epochs when the loss value doesn't decrease.\n    The training will stop when this number is reached.  batch_size : An integer. The batch size during the training.",
            "title": "Args"
        },
        {
            "location": "/generator/",
            "text": "",
            "title": "generator"
        },
        {
            "location": "/about/",
            "text": "About\n\n\nThis package is developed by \nDATA LAB\n at Texas A&M University.",
            "title": "About"
        },
        {
            "location": "/about/#about",
            "text": "This package is developed by  DATA LAB  at Texas A&M University.",
            "title": "About"
        }
    ]
}