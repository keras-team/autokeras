{
    "docs": [
        {
            "location": "/",
            "text": "This is a automated machine learning (AutoML) package based on Keras.\nIt aims at automatically search for the architecture and hyperparameters for deep learning models.\nThe ultimate goal for this project is for domain experts in fields other than computer science or machine learning\nto use deep learning models conveniently.\n\n\nTo install the package please use the commend as follows:\n\n\npip install autokeras\n\n\n\nHere is a short example for using the package.\n\n\nimport autokeras as ak\n\nclf = ak.ImageClassifier()\nclf.fit(x_train, y_train)\nresults = clf.predict(x_test)\n\n\n\nFor the repository on GitHub visit \nAuto-Keras on GitHub\n.\n\n\nIf you use Auto-Keras in a scientific publication, we would appreciate references to the following paper:\n\n\nEfficient Neural Architecture Search with Network Morphism.\nHaifeng Jin, Qingquan Song, Xia Hu.\n\narXiv:1806.10282\n.\n\n\nBiblatex entry:\n\n\n@online{jin2018efficient,\n  author       = {Haifeng Jin and Qingquan Song and Xia Hu},\n  title        = {Efficient Neural Architecture Search with Network Morphism},\n  date         = {2018-06-27},\n  year         = {2018},\n  eprintclass  = {cs.LG},\n  eprinttype   = {arXiv},\n  eprint       = {cs.LG/1806.10282},\n}",
            "title": "Home"
        },
        {
            "location": "/start/",
            "text": "Getting Started\n\n\nInstallation\n\n\nThe installation of Auto-Keras is the same as other python packages.\nJust use pip install.\nYou can run the following command in your terminal.\n\n\npip install autokeras\n\n\n\nExample\n\n\nHere we show an example of image classification on the MNIST dataset, is a famous image dataset for hand-written digits classification.\n\n\nfrom keras.datasets import mnist\nfrom autokeras.classifier import ImageClassifier\n\nif __name__ == '__main__':\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = x_train.reshape(x_train.shape + (1,))\n    x_test = x_test.reshape(x_test.shape + (1,))\n\n    clf = ImageClassifier(verbose=True)\n    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)\n    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)\n    y = clf.evaluate(x_test, y_test)\n    print(y)",
            "title": "Getting Started"
        },
        {
            "location": "/start/#getting-started",
            "text": "",
            "title": "Getting Started"
        },
        {
            "location": "/start/#installation",
            "text": "The installation of Auto-Keras is the same as other python packages.\nJust use pip install.\nYou can run the following command in your terminal.  pip install autokeras",
            "title": "Installation"
        },
        {
            "location": "/start/#example",
            "text": "Here we show an example of image classification on the MNIST dataset, is a famous image dataset for hand-written digits classification.  from keras.datasets import mnist\nfrom autokeras.classifier import ImageClassifier\n\nif __name__ == '__main__':\n    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n    x_train = x_train.reshape(x_train.shape + (1,))\n    x_test = x_test.reshape(x_test.shape + (1,))\n\n    clf = ImageClassifier(verbose=True)\n    clf.fit(x_train, y_train, time_limit=12 * 60 * 60)\n    clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)\n    y = clf.evaluate(x_test, y_test)\n    print(y)",
            "title": "Example"
        },
        {
            "location": "/classifier/",
            "text": "_validate\n\n\nCheck x_train's type and the shape of x_train, y_train.\n\n\nread_csv_file\n\n\nRead the cvs file and returns two seperate list containing images name and their labels\n\n\nArgs\n\n\ncsv_file_path\n: Path to the CVS file.\n\n\nReturns\n\n\nimg_file_names list containing images names and img_label list containing their respective labels.\n\n\nread_images\n\n\nReads the images from the path and return there numpy.ndarray instance\n\n\nArgs\n\n\nimg_file_names\n: List containing images names\n\n\nimages_dir_path\n: Path to directory containing images\n\n\nload_image_dataset\n\n\nLoad images from the files and labels from a csv file.\nSecond, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path. The path to the directory containing all the images should be passed through image_path.\n\n\nArgs\n\n\ncsv_file_path\n: CVS file path.\n\n\nimages_path\n: Path where images exist.\n\n\nReturns\n\n\nx: Four dimensional numpy.ndarray. The channel dimension is the last dimension. y: The labels.\n\n\nImageClassifier\n\n\nThe image classifier class.\nIt is used for image classification. It searches convolutional neural network architectures for the best configuration for the dataset.\n\n\nAttributes\n\n\npath\n: A path to the directory to save the classifier.\n\n\ny_encoder\n: An instance of OneHotEncoder for y_train (array of categorical labels).\n\n\nverbose\n: A boolean value indicating the verbosity mode.\n\n\nsearcher\n: An instance of BayesianSearcher. It search different\n    neural architecture to find the best model.\n\n\nsearcher_args\n: A dictionary containing the parameters for the searcher's \ninit\n function.\n\n\ninit\n\n\nInitialize the instance.\nThe classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.\n\n\nArgs\n\n\nverbose\n: An boolean of whether the search process will be printed to stdout.\n\n\npath\n: A string. The path to a directory, where the intermediate results are saved.\n\n\nresume\n: An boolean. If True, the classifier will continue to previous work saved in path.\n    Otherwise, the classifier will start a new search.\n\n\nfit\n\n\nFind the best neural architecture and train it.\nBased on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train, y_train.\n\n\nArgs\n\n\nx_train\n: An numpy.ndarray instance contains the training data.\n\n\ny_train\n: An numpy.ndarray instance contains the label of the training data.\n\n\ntime_limit\n: The time limit for the search in seconds.\n\n\npredict\n\n\nReturn predict result for the testing data.\n\n\nArgs\n\n\nx_test\n: An instance of numpy.ndarray contains the testing data.\n\n\nReturns\n\n\nAn numpy.ndarray containing the results.\n\n\nsummary\n\n\nPrint the summary of the best model.\n\n\nevaluate\n\n\nReturn the accuracy score between predict value and test_y.\n\n\nfinal_fit\n\n\nFinal training after found the best architecture.\n\n\nArgs\n\n\nx_train\n: An numpy.ndarray of training data.\n\n\ny_train\n: An numpy.ndarray of training targets.\n\n\nx_test\n: An numpy.ndarray of testing data.\n\n\ny_test\n: An numpy.ndarray of testing targets.\n\n\ntrainer_args\n: A dictionary containing the parameters of the ModelTrainer constructure.\n\n\nretrain\n: A boolean of whether reinitialize the weights of the model.\n\n\nexport_keras_model\n\n\nExport the searched model as a Keras saved model.\n\n\nArgs\n\n\npath\n: A string. The path to the file to save.\n\n\nmodel_id\n: A integer. If not provided, the function will export the best model.\n\n\nget_best_model_id\n\n\nReturns: An integer. The best model id.",
            "title": "classifier"
        },
        {
            "location": "/classifier/#_validate",
            "text": "Check x_train's type and the shape of x_train, y_train.",
            "title": "_validate"
        },
        {
            "location": "/classifier/#read_csv_file",
            "text": "Read the cvs file and returns two seperate list containing images name and their labels",
            "title": "read_csv_file"
        },
        {
            "location": "/classifier/#args",
            "text": "csv_file_path : Path to the CVS file.",
            "title": "Args"
        },
        {
            "location": "/classifier/#returns",
            "text": "img_file_names list containing images names and img_label list containing their respective labels.",
            "title": "Returns"
        },
        {
            "location": "/classifier/#read_images",
            "text": "Reads the images from the path and return there numpy.ndarray instance",
            "title": "read_images"
        },
        {
            "location": "/classifier/#args_1",
            "text": "img_file_names : List containing images names  images_dir_path : Path to directory containing images",
            "title": "Args"
        },
        {
            "location": "/classifier/#load_image_dataset",
            "text": "Load images from the files and labels from a csv file.\nSecond, the dataset is a set of images and the labels are in a CSV file. The CSV file should contain two columns whose names are 'File Name' and 'Label'. The file names in the first column should match the file names of the images with extensions, e.g., .jpg, .png. The path to the CSV file should be passed through the csv_file_path. The path to the directory containing all the images should be passed through image_path.",
            "title": "load_image_dataset"
        },
        {
            "location": "/classifier/#args_2",
            "text": "csv_file_path : CVS file path.  images_path : Path where images exist.",
            "title": "Args"
        },
        {
            "location": "/classifier/#returns_1",
            "text": "x: Four dimensional numpy.ndarray. The channel dimension is the last dimension. y: The labels.",
            "title": "Returns"
        },
        {
            "location": "/classifier/#imageclassifier",
            "text": "The image classifier class.\nIt is used for image classification. It searches convolutional neural network architectures for the best configuration for the dataset.",
            "title": "ImageClassifier"
        },
        {
            "location": "/classifier/#attributes",
            "text": "path : A path to the directory to save the classifier.  y_encoder : An instance of OneHotEncoder for y_train (array of categorical labels).  verbose : A boolean value indicating the verbosity mode.  searcher : An instance of BayesianSearcher. It search different\n    neural architecture to find the best model.  searcher_args : A dictionary containing the parameters for the searcher's  init  function.",
            "title": "Attributes"
        },
        {
            "location": "/classifier/#init",
            "text": "Initialize the instance.\nThe classifier will be loaded from the files in 'path' if parameter 'resume' is True. Otherwise it would create a new one.",
            "title": "init"
        },
        {
            "location": "/classifier/#args_3",
            "text": "verbose : An boolean of whether the search process will be printed to stdout.  path : A string. The path to a directory, where the intermediate results are saved.  resume : An boolean. If True, the classifier will continue to previous work saved in path.\n    Otherwise, the classifier will start a new search.",
            "title": "Args"
        },
        {
            "location": "/classifier/#fit",
            "text": "Find the best neural architecture and train it.\nBased on the given dataset, the function will find the best neural architecture for it. The dataset is in numpy.ndarray format. So they training data should be passed through x_train, y_train.",
            "title": "fit"
        },
        {
            "location": "/classifier/#args_4",
            "text": "x_train : An numpy.ndarray instance contains the training data.  y_train : An numpy.ndarray instance contains the label of the training data.  time_limit : The time limit for the search in seconds.",
            "title": "Args"
        },
        {
            "location": "/classifier/#predict",
            "text": "Return predict result for the testing data.",
            "title": "predict"
        },
        {
            "location": "/classifier/#args_5",
            "text": "x_test : An instance of numpy.ndarray contains the testing data.",
            "title": "Args"
        },
        {
            "location": "/classifier/#returns_2",
            "text": "An numpy.ndarray containing the results.",
            "title": "Returns"
        },
        {
            "location": "/classifier/#summary",
            "text": "Print the summary of the best model.",
            "title": "summary"
        },
        {
            "location": "/classifier/#evaluate",
            "text": "Return the accuracy score between predict value and test_y.",
            "title": "evaluate"
        },
        {
            "location": "/classifier/#final_fit",
            "text": "Final training after found the best architecture.",
            "title": "final_fit"
        },
        {
            "location": "/classifier/#args_6",
            "text": "x_train : An numpy.ndarray of training data.  y_train : An numpy.ndarray of training targets.  x_test : An numpy.ndarray of testing data.  y_test : An numpy.ndarray of testing targets.  trainer_args : A dictionary containing the parameters of the ModelTrainer constructure.  retrain : A boolean of whether reinitialize the weights of the model.",
            "title": "Args"
        },
        {
            "location": "/classifier/#export_keras_model",
            "text": "Export the searched model as a Keras saved model.",
            "title": "export_keras_model"
        },
        {
            "location": "/classifier/#args_7",
            "text": "path : A string. The path to the file to save.  model_id : A integer. If not provided, the function will export the best model.",
            "title": "Args"
        },
        {
            "location": "/classifier/#get_best_model_id",
            "text": "Returns: An integer. The best model id.",
            "title": "get_best_model_id"
        },
        {
            "location": "/search/",
            "text": "BayesianSearcher\n\n\nBase class of all searcher class\nThis class is the base class of all searcher class, every searcher class can override its search function to implements its strategy\n\n\nAttributes\n\n\nn_classes\n: number of classification\n\n\ninput_shape\n: Arbitrary, although all dimensions in the input shaped must be fixed.\n    Use the keyword argument input_shape (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.\n\n\nverbose\n: verbosity mode\n\n\nhistory\n: A list that stores the performance of model. Each element in it is a dictionary of 'model_id',\n    'loss', and 'accuracy'.\n\n\npath\n: A string. The path to the directory for saving the searcher.\n\n\nmodel_count\n: An integer. the total number of neural networks in the current searcher.\n\n\ndescriptors\n: A dictionary of all the neural networks architectures searched.\n\n\ntrainer_args\n: A dictionary. The params for the constructor of ModelTrainer.\n\n\ndefault_model_len\n: An integer. Number of convolutional layers in the initial architecture.\n\n\ndefault_model_width\n: An integer. The number of filters in each layer in the initial architecture.\n\n\ngpr\n: A GaussianProcessRegressor for bayesian optimization.\n\n\nsearch_tree\n: The data structure for storing all the searched architectures in tree structure.\n\n\ntraining_queue\n: A list of the generated architectures to be trained.\n\n\nx_queue\n: A list of trained architectures not updated to the gpr.\n\n\ny_queue\n: A list of trained architecture performances not updated to the gpr.\n\n\nbeta\n: A float. The beta in the UCB acquisition function.\n\n\nt_min\n: A float. The minimum temperature during simulated annealing.\n\n\ninit\n\n\nArgs: n_classes: An integer, the number of classes. input_shape: A tuple. e.g. (28, 28, 1). path: A string. The path to the directory to save the searcher. verbose: A boolean. Whether to output the intermediate information to stdout. trainer_args: A dictionary. The params for the constructor of ModelTrainer. default_model_len: An integer. Number of convolutional layers in the initial architecture. default_model_width: An integer. The number of filters in each layer in the initial architecture. beta: A float. The beta in the UCB acquisition function. kernel_lambda: A float. The balance factor in the neural network kernel. t_min: A float. The minimum temperature during simulated annealing.",
            "title": "search"
        },
        {
            "location": "/search/#bayesiansearcher",
            "text": "Base class of all searcher class\nThis class is the base class of all searcher class, every searcher class can override its search function to implements its strategy",
            "title": "BayesianSearcher"
        },
        {
            "location": "/search/#attributes",
            "text": "n_classes : number of classification  input_shape : Arbitrary, although all dimensions in the input shaped must be fixed.\n    Use the keyword argument input_shape (tuple of integers, does not include the batch axis)\n    when using this layer as the first layer in a model.  verbose : verbosity mode  history : A list that stores the performance of model. Each element in it is a dictionary of 'model_id',\n    'loss', and 'accuracy'.  path : A string. The path to the directory for saving the searcher.  model_count : An integer. the total number of neural networks in the current searcher.  descriptors : A dictionary of all the neural networks architectures searched.  trainer_args : A dictionary. The params for the constructor of ModelTrainer.  default_model_len : An integer. Number of convolutional layers in the initial architecture.  default_model_width : An integer. The number of filters in each layer in the initial architecture.  gpr : A GaussianProcessRegressor for bayesian optimization.  search_tree : The data structure for storing all the searched architectures in tree structure.  training_queue : A list of the generated architectures to be trained.  x_queue : A list of trained architectures not updated to the gpr.  y_queue : A list of trained architecture performances not updated to the gpr.  beta : A float. The beta in the UCB acquisition function.  t_min : A float. The minimum temperature during simulated annealing.",
            "title": "Attributes"
        },
        {
            "location": "/search/#init",
            "text": "Args: n_classes: An integer, the number of classes. input_shape: A tuple. e.g. (28, 28, 1). path: A string. The path to the directory to save the searcher. verbose: A boolean. Whether to output the intermediate information to stdout. trainer_args: A dictionary. The params for the constructor of ModelTrainer. default_model_len: An integer. Number of convolutional layers in the initial architecture. default_model_width: An integer. The number of filters in each layer in the initial architecture. beta: A float. The beta in the UCB acquisition function. kernel_lambda: A float. The balance factor in the neural network kernel. t_min: A float. The minimum temperature during simulated annealing.",
            "title": "init"
        },
        {
            "location": "/graph/",
            "text": "Graph\n\n\nA class represent the neural architecture graph of a Keras model.\nGraph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph.  Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.)\n\n\nAttributes\n\n\nweighted\n: A boolean of whether the weights and biases in the neural network\n    should be included in the graph.\n\n\ninput_shape\n: Tuple of integers, does not include the batch axis.\n\n\nnode_list\n: A list of integers, the indices of the list are the identifiers.\n\n\nlayer_list\n: A list of stub layers, the indices of the list are the identifiers.\n\n\nnode_to_id\n: A dict instance mapping from node integers to their identifiers.\n\n\nlayer_to_id\n: A dict instance mapping from stub layers to their identifiers.\n\n\nlayer_id_to_input_node_ids\n: A dict instance mapping from layer identifiers\n    to their input nodes identifiers.\n\n\nadj_list\n: A two dimensional list. The adjacency list of the graph. The first dimension is\n    identified by tensor identifiers. In each edge list, the elements are two-element tuples\n    of (tensor identifier, layer identifier).\n\n\nreverse_adj_list\n: A reverse adjacent list in the same format as adj_list.\n\n\noperation_history\n: A list saving all the network morphism operations.\n\n\nvis\n: A dictionary of temporary storage for whether an local operation has been done\n    during the network morphism.\n\n\nn_nodes\n\n\nReturn the number of nodes in the model.\n\n\nn_layers\n\n\nReturn the number of layers in the model.\n\n\n_add_node\n\n\nAdd node to node list if it not in node list.\n\n\n_add_edge\n\n\nAdd edge to the graph.\n\n\n_redirect_edge\n\n\nRedirect the edge to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same.\n\n\n_replace_layer\n\n\nReplace the layer with a new layer.\n\n\n_topological_order\n\n\nReturn the topological order of the node ids.\n\n\n_search\n\n\nSearch the graph for widening the layers.\n\n\nArgs\n\n\nu\n: The starting node identifier.\n\n\nstart_dim\n: The position to insert the additional dimensions.\n\n\ntotal_dim\n: The total number of dimensions the layer has before widening.\n\n\nn_add\n: The number of dimensions to add.\n\n\nto_conv_deeper_model\n\n\nInsert a relu-conv-bn block after the target block.\n\n\nArgs\n\n\ntarget_id\n: A convolutional layer ID. The new block should be inserted after the block.\n\n\nkernel_size\n: An integer. The kernel size of the new convolutional layer.\n\n\nto_wider_model\n\n\nWiden the last dimension of the output of the pre_layer.\n\n\nArgs\n\n\npre_layer_id\n: The ID of a convolutional layer or dense layer.\n\n\nn_add\n: The number of dimensions to add.\n\n\nto_dense_deeper_model\n\n\nInsert a dense layer after the target layer.\n\n\nArgs\n\n\ntarget_id\n: The ID of a dense layer.\n\n\n_conv_block_end_node\n\n\nGet the input node ID of the last layer in the block by layer ID.\n\n\nArgs\n\n\nlayer_id\n: the convolutional layer ID.\n\n\nReturns\n\n\nThe input node ID of the last layer in the convolutional block.\n\n\nto_add_skip_model\n\n\nAdd a weighted add skip connection from after start node to end node.\n\n\nArgs\n\n\nstart_id\n: The convolutional layer ID, after which to start the skip-connection.\n\n\nend_id\n: The convolutional layer ID, after which to end the skip-connection.\n\n\nto_concat_skip_model\n\n\nAdd a weighted add concatenate connection from after start node to end node.\n\n\nArgs\n\n\nstart_id\n: The convolutional layer ID, after which to start the skip-connection.\n\n\nend_id\n: The convolutional layer ID, after which to end the skip-connection.\n\n\nproduce_model\n\n\nBuild a new Keras model based on the current graph.",
            "title": "graph"
        },
        {
            "location": "/graph/#graph",
            "text": "A class represent the neural architecture graph of a Keras model.\nGraph extracts the neural architecture graph from a Keras model. Each node in the graph is a intermediate tensor between layers. Each layer is an edge in the graph.  Notably, multiple edges may refer to the same layer. (e.g. Add layer is adding two tensor into one tensor. So it is related to two edges.)",
            "title": "Graph"
        },
        {
            "location": "/graph/#attributes",
            "text": "weighted : A boolean of whether the weights and biases in the neural network\n    should be included in the graph.  input_shape : Tuple of integers, does not include the batch axis.  node_list : A list of integers, the indices of the list are the identifiers.  layer_list : A list of stub layers, the indices of the list are the identifiers.  node_to_id : A dict instance mapping from node integers to their identifiers.  layer_to_id : A dict instance mapping from stub layers to their identifiers.  layer_id_to_input_node_ids : A dict instance mapping from layer identifiers\n    to their input nodes identifiers.  adj_list : A two dimensional list. The adjacency list of the graph. The first dimension is\n    identified by tensor identifiers. In each edge list, the elements are two-element tuples\n    of (tensor identifier, layer identifier).  reverse_adj_list : A reverse adjacent list in the same format as adj_list.  operation_history : A list saving all the network morphism operations.  vis : A dictionary of temporary storage for whether an local operation has been done\n    during the network morphism.",
            "title": "Attributes"
        },
        {
            "location": "/graph/#n_nodes",
            "text": "Return the number of nodes in the model.",
            "title": "n_nodes"
        },
        {
            "location": "/graph/#n_layers",
            "text": "Return the number of layers in the model.",
            "title": "n_layers"
        },
        {
            "location": "/graph/#_add_node",
            "text": "Add node to node list if it not in node list.",
            "title": "_add_node"
        },
        {
            "location": "/graph/#_add_edge",
            "text": "Add edge to the graph.",
            "title": "_add_edge"
        },
        {
            "location": "/graph/#_redirect_edge",
            "text": "Redirect the edge to a new node. Change the edge originally from u_id to v_id into an edge from u_id to new_v_id while keeping all other property of the edge the same.",
            "title": "_redirect_edge"
        },
        {
            "location": "/graph/#_replace_layer",
            "text": "Replace the layer with a new layer.",
            "title": "_replace_layer"
        },
        {
            "location": "/graph/#_topological_order",
            "text": "Return the topological order of the node ids.",
            "title": "_topological_order"
        },
        {
            "location": "/graph/#_search",
            "text": "Search the graph for widening the layers.",
            "title": "_search"
        },
        {
            "location": "/graph/#args",
            "text": "u : The starting node identifier.  start_dim : The position to insert the additional dimensions.  total_dim : The total number of dimensions the layer has before widening.  n_add : The number of dimensions to add.",
            "title": "Args"
        },
        {
            "location": "/graph/#to_conv_deeper_model",
            "text": "Insert a relu-conv-bn block after the target block.",
            "title": "to_conv_deeper_model"
        },
        {
            "location": "/graph/#args_1",
            "text": "target_id : A convolutional layer ID. The new block should be inserted after the block.  kernel_size : An integer. The kernel size of the new convolutional layer.",
            "title": "Args"
        },
        {
            "location": "/graph/#to_wider_model",
            "text": "Widen the last dimension of the output of the pre_layer.",
            "title": "to_wider_model"
        },
        {
            "location": "/graph/#args_2",
            "text": "pre_layer_id : The ID of a convolutional layer or dense layer.  n_add : The number of dimensions to add.",
            "title": "Args"
        },
        {
            "location": "/graph/#to_dense_deeper_model",
            "text": "Insert a dense layer after the target layer.",
            "title": "to_dense_deeper_model"
        },
        {
            "location": "/graph/#args_3",
            "text": "target_id : The ID of a dense layer.",
            "title": "Args"
        },
        {
            "location": "/graph/#_conv_block_end_node",
            "text": "Get the input node ID of the last layer in the block by layer ID.",
            "title": "_conv_block_end_node"
        },
        {
            "location": "/graph/#args_4",
            "text": "layer_id : the convolutional layer ID.",
            "title": "Args"
        },
        {
            "location": "/graph/#returns",
            "text": "The input node ID of the last layer in the convolutional block.",
            "title": "Returns"
        },
        {
            "location": "/graph/#to_add_skip_model",
            "text": "Add a weighted add skip connection from after start node to end node.",
            "title": "to_add_skip_model"
        },
        {
            "location": "/graph/#args_5",
            "text": "start_id : The convolutional layer ID, after which to start the skip-connection.  end_id : The convolutional layer ID, after which to end the skip-connection.",
            "title": "Args"
        },
        {
            "location": "/graph/#to_concat_skip_model",
            "text": "Add a weighted add concatenate connection from after start node to end node.",
            "title": "to_concat_skip_model"
        },
        {
            "location": "/graph/#args_6",
            "text": "start_id : The convolutional layer ID, after which to start the skip-connection.  end_id : The convolutional layer ID, after which to end the skip-connection.",
            "title": "Args"
        },
        {
            "location": "/graph/#produce_model",
            "text": "Build a new Keras model based on the current graph.",
            "title": "produce_model"
        },
        {
            "location": "/preprocessor/",
            "text": "OneHotEncoder\n\n\nA class that can format data\nThis class provide ways to transform data's classification into vector\n\n\nAttributes\n\n\ndata\n: the input data\n\n\nn_classes\n: the number of classification\n\n\nlabels\n: the number of label\n\n\nlabel_to_vec\n: mapping from label to vector\n\n\nint_to_label\n: mapping from int to label\n\n\ninit\n\n\nInit OneHotEncoder\n\n\nfit\n\n\nCreate mapping from label to vector, and vector to label\n\n\ntransform\n\n\nGet vector for every element in the data array\n\n\ninverse_transform\n\n\nGet label for every element in data",
            "title": "preprocessor"
        },
        {
            "location": "/preprocessor/#onehotencoder",
            "text": "A class that can format data\nThis class provide ways to transform data's classification into vector",
            "title": "OneHotEncoder"
        },
        {
            "location": "/preprocessor/#attributes",
            "text": "data : the input data  n_classes : the number of classification  labels : the number of label  label_to_vec : mapping from label to vector  int_to_label : mapping from int to label",
            "title": "Attributes"
        },
        {
            "location": "/preprocessor/#init",
            "text": "Init OneHotEncoder",
            "title": "init"
        },
        {
            "location": "/preprocessor/#fit",
            "text": "Create mapping from label to vector, and vector to label",
            "title": "fit"
        },
        {
            "location": "/preprocessor/#transform",
            "text": "Get vector for every element in the data array",
            "title": "transform"
        },
        {
            "location": "/preprocessor/#inverse_transform",
            "text": "Get label for every element in data",
            "title": "inverse_transform"
        },
        {
            "location": "/utils/",
            "text": "ensure_dir\n\n\nCreate directory if it does not exist\n\n\nensure_file_dir\n\n\nCreate path if it does not exist\n\n\nModelTrainer\n\n\nA class that is used to train model\nThis class can train a model with dataset and will not stop until getting minimum loss\n\n\nAttributes\n\n\nmodel\n: the model that will be trained\n\n\nx_train\n: the input train data\n\n\ny_train\n: the input train data labels\n\n\nx_test\n: the input test data\n\n\ny_test\n: the input test data labels\n\n\nverbose\n: verbosity mode\n\n\ninit\n\n\nInit ModelTrainer with model, x_train, y_train, x_test, y_test, verbose\n\n\ntrain_model\n\n\nTrain the model.\n\n\nArgs\n\n\nmax_iter_num\n: An integer. The maximum number of epochs to train the model.\n    The training will stop when this number is reached.\n\n\nmax_no_improvement_num\n: An integer. The maximum number of epochs when the loss value doesn't decrease.\n    The training will stop when this number is reached.\n\n\nbatch_size\n: An integer. The batch size during the training.\n\n\noptimizer\n: An optimizer class.\n\n\naugment\n: A boolean of whether the data will be augmented.",
            "title": "utils"
        },
        {
            "location": "/utils/#ensure_dir",
            "text": "Create directory if it does not exist",
            "title": "ensure_dir"
        },
        {
            "location": "/utils/#ensure_file_dir",
            "text": "Create path if it does not exist",
            "title": "ensure_file_dir"
        },
        {
            "location": "/utils/#modeltrainer",
            "text": "A class that is used to train model\nThis class can train a model with dataset and will not stop until getting minimum loss",
            "title": "ModelTrainer"
        },
        {
            "location": "/utils/#attributes",
            "text": "model : the model that will be trained  x_train : the input train data  y_train : the input train data labels  x_test : the input test data  y_test : the input test data labels  verbose : verbosity mode",
            "title": "Attributes"
        },
        {
            "location": "/utils/#init",
            "text": "Init ModelTrainer with model, x_train, y_train, x_test, y_test, verbose",
            "title": "init"
        },
        {
            "location": "/utils/#train_model",
            "text": "Train the model.",
            "title": "train_model"
        },
        {
            "location": "/utils/#args",
            "text": "max_iter_num : An integer. The maximum number of epochs to train the model.\n    The training will stop when this number is reached.  max_no_improvement_num : An integer. The maximum number of epochs when the loss value doesn't decrease.\n    The training will stop when this number is reached.  batch_size : An integer. The batch size during the training.  optimizer : An optimizer class.  augment : A boolean of whether the data will be augmented.",
            "title": "Args"
        },
        {
            "location": "/generator/",
            "text": "RandomConvClassifierGenerator\n\n\ngenerate\n\n\nReturn the random generated CNN model.",
            "title": "generator"
        },
        {
            "location": "/generator/#randomconvclassifiergenerator",
            "text": "",
            "title": "RandomConvClassifierGenerator"
        },
        {
            "location": "/generator/#generate",
            "text": "Return the random generated CNN model.",
            "title": "generate"
        },
        {
            "location": "/about/",
            "text": "About\n\n\nThis package is developed by \nDATA LAB\n at Texas A&M University.",
            "title": "About"
        },
        {
            "location": "/about/#about",
            "text": "This package is developed by  DATA LAB  at Texas A&M University.",
            "title": "About"
        }
    ]
}