{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Regression tasks estimate a numeric variable, such as the price of a house or voter\n",
    "turnout.\n",
    "\n",
    "This example is adapted from a\n",
    "[notebook](https://gist.github.com/mapmeld/98d1e9839f2d1f9c4ee197953661ed07) which\n",
    "estimates a person's age from their image, trained on the\n",
    "[IMDB-WIKI](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/) photographs of famous\n",
    "people.\n",
    "\n",
    "First, prepare your image data in a numpy.ndarray or tensorflow.Dataset format. Each\n",
    "image must have the same shape, meaning each has the same width, height, and color\n",
    "channels as other images in the set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Connect your Google Drive for Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from google.colab import drive\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "import autokeras as ak\n",
    "drive.mount(\"/content/drive\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Install AutoKeras and TensorFlow\n",
    "\n",
    "Download the master branch to your Google Drive for this tutorial. In general, you can\n",
    "use *pip install autokeras* .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!!pip install  -v \"/content/drive/My Drive/AutoKeras-dev/autokeras-master.zip\"\n",
    "!!pip uninstall keras-tuner\n",
    "!!pip install\n",
    "!git+git://github.com/keras-team/keras-tuner.git@d2d69cba21a0b482a85ce2a38893e2322e139c01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!!pip install tensorflow==2.2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "###**Import IMDB Celeb images and metadata**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!!mkdir ./drive/My\\ Drive/mlin/celebs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!! wget -O ./drive/My\\ Drive/mlin/celebs/imdb_0.tar\n",
    "!https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_0.tar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!! cd ./drive/My\\ Drive/mlin/celebs && tar -xf imdb_0.tar\n",
    "!! rm ./drive/My\\ Drive/mlin/celebs/imdb_0.tar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "Uncomment and run the below cell if you need to re-run the cells again and above don't\n",
    "need to install everything from the beginning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# ! cd ./drive/My\\ Drive/mlin/celebs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!! ls ./drive/My\\ Drive/mlin/celebs/imdb/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "!! wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/imdb_meta.tar\n",
    "!! tar -xf imdb_meta.tar\n",
    "!! rm imdb_meta.tar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "###**Converting from MATLAB date to actual Date-of-Birth**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def datenum_to_datetime(datenum):\n",
    "    \"\"\"\n",
    "    Convert Matlab datenum into Python datetime.\n",
    "    \"\"\"\n",
    "    days = datenum % 1\n",
    "    hours = days % 1 * 24\n",
    "    minutes = hours % 1 * 60\n",
    "    seconds = minutes % 1 * 60\n",
    "    try:\n",
    "        return (\n",
    "            datetime.fromordinal(int(datenum))\n",
    "            + timedelta(days=int(days))\n",
    "            + timedelta(hours=int(hours))\n",
    "            + timedelta(minutes=int(minutes))\n",
    "            + timedelta(seconds=round(seconds))\n",
    "            - timedelta(days=366)\n",
    "        )\n",
    "    except:\n",
    "        return datenum_to_datetime(700000)\n",
    "\n",
    "\n",
    "print(datenum_to_datetime(734963))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **Opening MatLab file to Pandas DataFrame**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "x = loadmat(\"imdb/imdb.mat\")\n",
    "\n",
    "\n",
    "mdata = x[\"imdb\"]  # variable in mat file\n",
    "mdtype = mdata.dtype  # dtypes of structures are \"unsized objects\"\n",
    "ndata = {n: mdata[n][0, 0] for n in mdtype.names}\n",
    "columns = [n for n, v in ndata.items()]\n",
    "\n",
    "rows = []\n",
    "for col in range(0, 10):\n",
    "    values = list(ndata.items())[col]\n",
    "    for num, val in enumerate(values[1][0], start=0):\n",
    "        if col == 0:\n",
    "            rows.append([])\n",
    "        if num > 0:\n",
    "            if columns[col] == \"dob\":\n",
    "                rows[num].append(datenum_to_datetime(int(val)))\n",
    "            elif columns[col] == \"photo_taken\":\n",
    "                rows[num].append(datetime(year=int(val), month=6, day=30))\n",
    "            else:\n",
    "                rows[num].append(val)\n",
    "\n",
    "dt = map(lambda row: np.array(row), np.array(rows[1:]))\n",
    "\n",
    "df = pd.DataFrame(data=dt, index=range(0, len(rows) - 1), columns=columns)\n",
    "print(df.head())\n",
    "\n",
    "print(columns)\n",
    "print(df[\"full_path\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **Calculating age at time photo was taken**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "df[\"age\"] = (df[\"photo_taken\"] - df[\"dob\"]).astype(\"int\") / 31558102e9\n",
    "print(df[\"age\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **Creating dataset**\n",
    "\n",
    "\n",
    "* We sample 200 of the images which were included in this first download.\n",
    "* Images are resized to 128x128 to standardize shape and conserve memory\n",
    "* RGB images are converted to grayscale to standardize shape\n",
    "* Ages are converted to ints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def df2numpy(train_set):\n",
    "    images = []\n",
    "    for img_path in train_set[\"full_path\"]:\n",
    "        img = (\n",
    "            Image.open(\"./drive/My Drive/mlin/celebs/imdb/\" + img_path[0])\n",
    "            .resize((128, 128))\n",
    "            .convert(\"L\")\n",
    "        )\n",
    "        images.append(np.asarray(img, dtype=\"int32\"))\n",
    "\n",
    "    image_inputs = np.array(images)\n",
    "\n",
    "    ages = train_set[\"age\"].astype(\"int\").to_numpy()\n",
    "    return image_inputs, ages\n",
    "\n",
    "\n",
    "train_set = df[df[\"full_path\"] < \"02\"].sample(200)\n",
    "train_imgs, train_ages = df2numpy(train_set)\n",
    "\n",
    "test_set = df[df[\"full_path\"] < \"02\"].sample(100)\n",
    "test_imgs, test_ages = df2numpy(test_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **Training using AutoKeras**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the image regressor\n",
    "reg = ak.ImageRegressor(max_trials=15)  # AutoKeras tries 15 different models.\n",
    "\n",
    "# Find the best model for the given training data\n",
    "reg.fit(train_imgs, train_ages)\n",
    "\n",
    "# Predict with the chosen model:\n",
    "# predict_y = reg.predict(test_images)  # Uncomment if required\n",
    "\n",
    "# Evaluate the chosen model with testing data\n",
    "print(reg.evaluate(test_images, test_ages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **Validation Data**\n",
    "\n",
    "By default, AutoKeras use the last 20% of training data as validation data. As shown in\n",
    "the example below, you can use validation_split to specify the percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "reg.fit(\n",
    "    train_imgs,\n",
    "    train_ages,\n",
    "    # Split the training data and use the last 15% as validation data.\n",
    "    validation_split=0.15,\n",
    "    epochs=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "You can also use your own validation set instead of splitting it from the training data\n",
    "with validation_data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "split = 460000\n",
    "x_val = train_imgs[split:]\n",
    "y_val = train_ages[split:]\n",
    "x_train = train_imgs[:split]\n",
    "y_train = train_ages[:split]\n",
    "reg.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    # Use your own validation set.\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **Customized Search Space**\n",
    "\n",
    "For advanced users, you may customize your search space by using AutoModel instead of\n",
    "ImageRegressor. You can configure the ImageBlock for some high-level configurations,\n",
    "e.g., block_type for the type of neural network to search, normalize for whether to do\n",
    "data normalization, augment for whether to do data augmentation. You can also choose not\n",
    "to specify these arguments, which would leave the different choices to be tuned\n",
    "automatically. See the following example for detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_node = ak.ImageInput()\n",
    "output_node = ak.ImageBlock(\n",
    "    # Only search ResNet architectures.\n",
    "    block_type=\"resnet\",\n",
    "    # Normalize the dataset.\n",
    "    normalize=True,\n",
    "    # Do not do data augmentation.\n",
    "    augment=False,\n",
    ")(input_node)\n",
    "output_node = ak.RegressionHead()(output_node)\n",
    "reg = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "reg.fit(x_train, y_train, epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The usage of AutoModel is similar to the functional API of Keras. Basically, you are\n",
    "building a graph, whose edges are blocks and the nodes are intermediate outputs of\n",
    "blocks. To add an edge from input_node to output_node with output_node =\n",
    "ak.some_block(input_node).\n",
    "You can even also use more fine grained blocks to customize the search space even\n",
    "further. See the following example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_node = ak.ImageInput()\n",
    "output_node = ak.Normalization()(input_node)\n",
    "output_node = ak.ImageAugmentation(translation_factor=0.3)(output_node)\n",
    "output_node = ak.ResNetBlock(version=\"v2\")(output_node)\n",
    "output_node = ak.RegressionHead()(output_node)\n",
    "clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=10)\n",
    "clf.fit(x_train, y_train, epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### **Data Format**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The AutoKeras ImageClassifier is quite flexible for the data format.\n",
    "\n",
    "For the image, it accepts data formats both with and without the channel dimension. The\n",
    "images in the IMDB-Wiki dataset do not have a channel dimension. Each image is a matrix\n",
    "with shape (128, 128). AutoKeras also accepts images with a channel dimension at last,\n",
    "e.g., (32, 32, 3), (28, 28, 1).\n",
    "\n",
    "For the classification labels, AutoKeras accepts both plain labels, i.e. strings or\n",
    "integers, and one-hot encoded labels, i.e. vectors of 0s and 1s.\n",
    "\n",
    "So if you prepare your data in the following way, the ImageClassifier should still work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Reshape the images to have the channel dimension.\n",
    "train_imgs = train_imgs.reshape(train_imgs.shape + (1,))\n",
    "test_imgs = test_imgs.reshape(test_imgs.shape + (1,))\n",
    "\n",
    "print(train_imgs.shape)  # (200, 128, 128, 1)\n",
    "print(test_imgs.shape)  # (100, 128, 128, 1)\n",
    "print(train_ages[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "We also support using tf.data.Dataset format for the training data. In this case, the\n",
    "images would have to be 3-dimentional. The labels have to be one-hot encoded for\n",
    "multi-class classification to be wrapped into tensorflow Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices(((train_imgs,), (train_ages,)))\n",
    "test_set = tf.data.Dataset.from_tensor_slices(((test_imgs,), (test_ages,)))\n",
    "\n",
    "reg = ak.ImageRegressor(max_trials=15)\n",
    "# Feed the tensorflow Dataset to the classifier.\n",
    "reg.fit(train_set)\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(test_set)\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(test_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## References\n",
    "\n",
    "[Main Reference\n",
    "Notebook](https://gist.github.com/mapmeld/98d1e9839f2d1f9c4ee197953661ed07),\n",
    "[Dataset](https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/),\n",
    "[ImageRegressor](/image_regressor),\n",
    "[ResNetBlock](/block/#resnetblock-class),\n",
    "[ImageInput](/node/#imageinput-class),\n",
    "[AutoModel](/auto_model/#automodel-class),\n",
    "[ImageBlock](/block/#imageblock-class),\n",
    "[Normalization](/preprocessor/#normalization-class),\n",
    "[ImageAugmentation](/preprocessor/#image-augmentation-class),\n",
    "[RegressionHead](/head/#regressionhead-class).\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_regression",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}